import os
# --- 1. ã€é­”æ³•ä»£ç ã€‘è®¾ç½®å›½å†…é•œåƒæº (è§£å†³ HuggingFace è¿ä¸ä¸Šçš„é—®é¢˜) ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# --- 2. æ­£å¸¸çš„ Import ---
from langchain_community.document_loaders import Docx2txtLoader, PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.vectorstores import FAISS

# --- 3. é…ç½®è·¯å¾„ ---
DATA_PATH = "./data"
DB_PATH = "./vector_db"

# --- 4. åŠ è½½æ–‡æ¡£ ---
def load_documents():
    documents = []
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
        print(f"âš ï¸ è¯·å°†ä½ çš„ .docx æˆ– .pdf æ–‡ä»¶æ”¾å…¥ {DATA_PATH} æ–‡ä»¶å¤¹ä¸­ï¼")
        return []

    for file in os.listdir(DATA_PATH):
        if file.startswith("~$"): # è·³è¿‡ä¸´æ—¶æ–‡ä»¶
            continue
            
        file_path = os.path.join(DATA_PATH, file)
        ext = os.path.splitext(file)[1].lower()
        
        loader = None
        if ext == ".docx":
            loader = Docx2txtLoader(file_path)
        elif ext == ".pdf":
            loader = PyPDFLoader(file_path)
        elif ext == ".txt":
            loader = TextLoader(file_path, encoding="utf-8")
            
        if loader:
            try:
                print(f"æ­£åœ¨åŠ è½½æ–‡ä»¶: {file}...")
                documents.extend(loader.load())
            except Exception as e:
                print(f"âŒ è·³è¿‡æŸåæ–‡ä»¶: {file} ({e})")
                
    return documents

# --- 5. ä¸»å‡½æ•° ---
def create_vector_db():
    docs = load_documents()
    if not docs:
        print("âš ï¸ æ²¡æ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·æ£€æŸ¥ data æ–‡ä»¶å¤¹ã€‚")
        return

    print(f"æ­£åœ¨åˆ‡åˆ† {len(docs)} ä»½æ–‡æ¡£...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)
    split_docs = text_splitter.split_documents(docs)
    print(f"å…±åˆ‡åˆ†ä¸º {len(split_docs)} ä¸ªç‰‡æ®µã€‚")

    print("æ­£åœ¨ä¸‹è½½ Embedding æ¨¡å‹ (ä½¿ç”¨å›½å†…é•œåƒ)...")
    try:
        # å°è¯•ä½¿ç”¨ GPU
        embeddings = HuggingFaceBgeEmbeddings(
            model_name="BAAI/bge-small-zh-v1.5",
            model_kwargs={'device': 'cuda'},
            encode_kwargs={'normalize_embeddings': True}
        )
    except:
        print("GPU åŠ è½½å¤±è´¥ï¼Œåˆ‡æ¢å› CPU æ¨¡å¼ (è¿™å¾ˆæ­£å¸¸ï¼Œä¸å½±å“ä½¿ç”¨)...")
        embeddings = HuggingFaceBgeEmbeddings(
            model_name="BAAI/bge-small-zh-v1.5",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )

    print("æ­£åœ¨æ„å»ºç´¢å¼•...")
    db = FAISS.from_documents(split_docs, embeddings)
    db.save_local(DB_PATH)
    print(f"ğŸ‰ æˆåŠŸï¼çŸ¥è¯†åº“å·²ä¿å­˜åˆ° {DB_PATH}")

if __name__ == "__main__":
    create_vector_db()